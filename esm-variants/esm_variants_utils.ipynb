{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aUV6kgdrA5m6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "AAorder=['K','R','H','E','D','N','Q','T','S','C','G','A','V','L','I','M','P','Y','F','W']\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "##### INFERENCE\n",
    "def load_esm_model(model_name,device=0):\n",
    "  import torch\n",
    "  repr_layer = int(model_name.split('_')[1][1:])\n",
    "  model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", model_name)\n",
    "  batch_converter = alphabet.get_batch_converter() \n",
    "  return model.eval().to(device),alphabet,batch_converter,repr_layer\n",
    "\n",
    "def get_wt_LLR(input_df,device=0,silent=False): \n",
    "  # input: df.columns= id,\tgene,\tseq, length\n",
    "  # requires global model and batch_converter\n",
    "  # make sure input_df does not contain any nonstandard amino acids\n",
    "  AAorder=['K','R','H','E','D','N','Q','T','S','C','G','A','V','L','I','M','P','Y','F','W']\n",
    "  genes = input_df.id.values\n",
    "  LLRs=[];input_df_ids=[]\n",
    "  for gname in tqdm(genes,disable=silent):\n",
    "    seq_length=input_df[input_df.id==gname].length.values[0]\n",
    "    \n",
    "    if seq_length<=1022:\n",
    "      dt = [(gname+'_WT',input_df[input_df.id==gname].seq.values[0])]\n",
    "      batch_labels, batch_strs, batch_tokens = batch_converter(dt)\n",
    "      with torch.no_grad():\n",
    "        results_ = torch.log_softmax(model(batch_tokens.to(device), repr_layers=[33], return_contacts=False)['logits'],dim=-1)\n",
    "\n",
    "      WTlogits = pd.DataFrame(results_[0,:,:].cpu().numpy()[1:-1,:],columns=alphabet.all_toks,index=list(input_df[input_df.id==gname].seq.values[0])).T.iloc[4:24].loc[AAorder]\n",
    "      WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
    "      wt_norm=np.diag(WTlogits.loc[[i.split(' ')[0] for i in WTlogits.columns]])\n",
    "      LLR = WTlogits - wt_norm\n",
    "\n",
    "      LLRs += [LLR]\n",
    "      input_df_ids+=[gname]\n",
    "\n",
    "    else: ### tiling\n",
    "      long_seq = input_df[input_df.id==gname].seq.values[0]\n",
    "      ints,M,M_norm = get_intervals_and_weights(len(long_seq),min_overlap=512,max_len=1022,s=20)\n",
    "      \n",
    "      dt = []\n",
    "      for i,idx in enumerate(ints):\n",
    "        dt += [(gname+'_WT_'+str(i),''.join(list(np.array(list(long_seq))[idx])) )]\n",
    "\n",
    "      logit_parts = []\n",
    "      for dt_ in chunks(dt,20):\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(dt_)\n",
    "        with torch.no_grad():\n",
    "          results_ = torch.log_softmax(model(batch_tokens.to(device), repr_layers=[33], return_contacts=False)['logits'],dim=-1)\n",
    "        for i in range(results_.shape[0]):\n",
    "          logit_parts += [results_[i,:,:].cpu().numpy()[1:-1,:]]\n",
    "          \n",
    "      logits_full = np.zeros((len(long_seq),33))\n",
    "      for i in range(len(ints)):\n",
    "        logit = np.zeros((len(long_seq),33))\n",
    "        logit[ints[i]] = logit_parts[i].copy()\n",
    "        logit = np.multiply(logit.T, M_norm[i,:]).T\n",
    "        logits_full+=logit\n",
    "        \n",
    "      WTlogits = pd.DataFrame(logits_full,columns=alphabet.all_toks,index=list(input_df[input_df.id==gname].seq.values[0])).T.iloc[4:24].loc[AAorder]\n",
    "      WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
    "      wt_norm=np.diag(WTlogits.loc[[i.split(' ')[0] for i in WTlogits.columns]])\n",
    "      LLR = WTlogits - wt_norm\n",
    "\n",
    "      LLRs += [LLR]\n",
    "      input_df_ids+=[gname]\n",
    "\n",
    "  return input_df_ids,LLRs\n",
    "\n",
    "def get_logits(seq,format=None,device=0):\n",
    "  data = [ (\"_\", seq),]\n",
    "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "  batch_tokens = batch_tokens.to(device)\n",
    "  with torch.no_grad():\n",
    "      logits = torch.log_softmax(model(batch_tokens, repr_layers=[33], return_contacts=False)[\"logits\"],dim=-1).cpu().numpy()\n",
    "  if format=='pandas':\n",
    "    WTlogits = pd.DataFrame(logits[0][1:-1,:],columns=alphabet.all_toks,index=list(seq)).T.iloc[4:24].loc[AAorder]\n",
    "    WTlogits.columns = [j.split('.')[0]+' '+str(i+1) for i,j in enumerate(WTlogits.columns)]\n",
    "    return WTlogits\n",
    "  else:\n",
    "    return logits[0][1:-1,:]\n",
    "\n",
    "def get_PLL(seq,reduce=np.sum,device=0):\n",
    "  s=get_logits(seq,device)\n",
    "  idx=[alphabet.tok_to_idx[i] for i in seq]\n",
    "  return reduce(np.diag(s[:,idx]))\n",
    "\n",
    "### MELTed CSV\n",
    "def meltLLR(LLR,savedir=None):\n",
    "  vars = LLR.melt(ignore_index=False)\n",
    "  vars['variant'] = [''.join(i.split(' '))+j for i,j in zip(vars['variable'],vars.index)]\n",
    "  vars['score'] = vars['value']\n",
    "  vars = vars.set_index('variant')\n",
    "  vars['pos'] = [int(i[1:-1]) for i in vars.index]\n",
    "  del vars['variable'],vars['value']\n",
    "  if savedir is not None:\n",
    "      vars.to_csv(savedir+'var_scores.csv')\n",
    "  return vars\n",
    "\n",
    "##################### TILING utils ###########################\n",
    "\n",
    "def chop(L,min_overlap=511,max_len=1022):\n",
    "  return L[max_len-min_overlap:-max_len+min_overlap]\n",
    "\n",
    "def intervals(L,min_overlap=511,max_len=1022,parts=None):\n",
    "  if parts is None: parts = []\n",
    "  #print('L:',len(L))\n",
    "  #print(len(parts))\n",
    "  if len(L)<=max_len:\n",
    "    if parts[-2][-1]-parts[-1][0]<min_overlap:\n",
    "      #print('DIFF:',parts[-2][-1]-parts[-1][0])\n",
    "      return parts+[np.arange(L[int(len(L)/2)]-int(max_len/2),L[int(len(L)/2)]+int(max_len/2)) ]\n",
    "    else:\n",
    "      return parts\n",
    "  else:\n",
    "    parts+=[L[:max_len],L[-max_len:]]\n",
    "    L=chop(L,min_overlap,max_len)\n",
    "    return intervals(L,min_overlap,max_len,parts=parts)\n",
    "\n",
    "def get_intervals_and_weights(seq_len,min_overlap=511,max_len=1022,s=16):\n",
    "  ints=intervals(np.arange(seq_len),min_overlap=min_overlap,max_len=max_len)\n",
    "  ## sort intervals\n",
    "  ints = [ints[i] for i in np.argsort([i[0] for i in ints])]\n",
    "\n",
    "  a=int(np.round(min_overlap/2))\n",
    "  t=np.arange(max_len)\n",
    "\n",
    "  f=np.ones(max_len)\n",
    "  f[:a] = 1 / (1 + np.exp(-(t[:a]-a/2)/s))\n",
    "  f[max_len-a:] = 1 / (1 + np.exp((t[:a]-a/2)/s))\n",
    "\n",
    "  f0=np.ones(max_len)\n",
    "  f0[max_len-a:] = 1 / (1 + np.exp((t[:a]-a/2)/s))\n",
    "\n",
    "  fn=np.ones(max_len)\n",
    "  fn[:a] = 1 / (1 + np.exp(-(t[:a]-a/2)/s))\n",
    "\n",
    "  filt=[f0]+[f for i in ints[1:-1]]+[fn]\n",
    "  M = np.zeros((len(ints),seq_len))\n",
    "  for k,i in enumerate(ints):\n",
    "    M[k,i] = filt[k]\n",
    "  M_norm = M/M.sum(0)\n",
    "  return (ints, M, M_norm)\n",
    "\n",
    "\n",
    "## PLLR score for indels\n",
    "def get_PLLR(wt_seq,mut_seq,start_pos,weighted=False):\n",
    "  fn=np.sum if not weighted else np.mean\n",
    "  if max(len(wt_seq),len(mut_seq))<=1022:\n",
    "    return  get_PLL(mut_seq,fn) - get_PLL(wt_seq,fn)\n",
    "  else:\n",
    "    wt_seq,mut_seq,start_pos = crop_indel(wt_seq,mut_seq,start_pos)\n",
    "    return  get_PLL(mut_seq,fn) - get_PLL(wt_seq,fn)\n",
    "\n",
    "def crop_indel(ref_seq,alt_seq,ref_start):\n",
    "  # Start pos: 1-indexed start position of variant\n",
    "  left_pos = ref_start-1\n",
    "  offset = len(ref_seq)-len(alt_seq)\n",
    "  start_pos = int(left_pos - 1022 / 2)\n",
    "  end_pos1 = int(left_pos + 1022 / 2) -min(start_pos,0)+ min(offset,0)\n",
    "  end_pos2 = int(left_pos + 1022 / 2) -min(start_pos,0)- max(offset,0)\n",
    "  if start_pos < 0: start_pos = 0 # Make sure the start position is not negative\n",
    "  if end_pos1 > len(ref_seq): end_pos1 = len(ref_seq) # Make sure the end positions are not beyond the end of the sequence\n",
    "  if end_pos2 > len(alt_seq): end_pos2 = len(alt_seq)\n",
    "  if start_pos>0 and max(end_pos2,end_pos1) - start_pos <1022: ## extend to the left if there's space\n",
    "            start_pos = max(0,max(end_pos2,end_pos1)-1022)\n",
    "\n",
    "  return ref_seq[start_pos:end_pos1],alt_seq[start_pos:end_pos2],start_pos-ref_start\n",
    "\n",
    "## stop gain variant score\n",
    "def get_minLLR(seq,stop_pos):\n",
    "  return min(get_wt_LLR(pd.DataFrame([('_','_',seq,len(seq))],columns=['id','gene','seq','length'] ),silent=True)[1][0].values[:,stop_pos:].reshape(-1))\n",
    "\n",
    "\n",
    "# ############### EXAMLE ##################\n",
    "# ## Load model\n",
    "# model,alphabet,batch_converter,repr_layer = load_esm_model(model_name='esm1b_t33_650M_UR50S',device='cuda')\n",
    "# ## Create a toy dataset\n",
    "# df_in = pd.DataFrame([('P1','gene1','FISHWISHFQRCHIPSTHATARECRISP',28),\n",
    "#                       ('P2','gene2','RAGEAGAINSTTHEMACHINE',21),\n",
    "#                       ('P3','gene3','SHIPSSAILASFISHSWIM',19),\n",
    "#                       ('P4','gene4','A'*1948,1948)], columns = ['id','gene','seq','length'])\n",
    "# ## Get LLRs\n",
    "# ids,LLRs = get_wt_LLR(df_in)\n",
    "# for i,LLR in zip(ids,LLRs):\n",
    "#   print(i,LLR.shape)\n",
    "# ## Get PLL\n",
    "# print(get_PLL(df_in.seq.values[0]))\n",
    "# ## indel: 14_IPS_delins_EESE (FISHWISHFQRCHIPSTHATARECRISP --> FISHWISHFQRCHEESETHATARECRISP)\n",
    "# get_PLLR('FISHWISHFQRCHIPSTHATARECRISP','FISHWISHFQRCHEESETHATARECRISP',14)\n",
    "# ## stop at position 17\n",
    "# get_minLLR(df_in.seq.values[0],17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZShMiadyO-uq"
   },
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clIbHRwrCYww",
    "outputId": "ba5bb3bd-5ea9-4688-db0d-218b4d6190df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "model,alphabet,batch_converter,repr_layer = load_esm_model(model_name='esm1b_t33_650M_UR50S',device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "45N6RSGoPB-m"
   },
   "outputs": [],
   "source": [
    "##create a toy dataset\n",
    "df_in = pd.DataFrame([('P1','gene1','FISHWISHFQRCHIPSTHATARECRISP',28),\n",
    "                      ('P2','gene2','RAGEAGAINSTTHEMACHINE',21),\n",
    "                      ('P3','gene3','SHIPSSAILASFISHSWIM',19),\n",
    "                      ('P4','gene4','A'*1948,1948)], columns = ['id','gene','seq','length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noYpT2fbPEFc",
    "outputId": "028259ed-0858-4d13-93cd-fc50b75f4170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "## Get LLRs\n",
    "ids,LLRs = get_wt_LLR(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ubRTY_4Pr2L",
    "outputId": "29722d7a-7cb9-409d-808c-99e9577a5210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 (20, 28)\n",
      "P2 (20, 21)\n",
      "P3 (20, 19)\n",
      "P4 (20, 1948)\n"
     ]
    }
   ],
   "source": [
    "for i,LLR in zip(ids,LLRs):\n",
    "  print(i,LLR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wk8M2c31PtmA",
    "outputId": "7d617123-4831-41df-a749-462fe200aa09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.311695"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_PLL(df_in.seq.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vP2KRAC6AaRS",
    "outputId": "a7064e66-d9de-49b4-9cfe-13a759737561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0078125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indel 14_IPS_delins_EESE (FISHWISHFQRCHIPSTHATARECRISP --> FISHWISHFQRCHEESETHATARECRISP)\n",
    "get_PLLR('FISHWISHFQRCHIPSTHATARECRISP','FISHWISHFQRCHEESETHATARECRISP',14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydAO4K9HAOX2",
    "outputId": "f94a6537-c0b7-463e-c083-5051ad367348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.1914926"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop at position 17\n",
    "get_minLLR(df_in.seq.values[0],17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_WwmsxmIDZ5p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
